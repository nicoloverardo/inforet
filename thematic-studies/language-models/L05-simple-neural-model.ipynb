{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Neural Network Model\n",
    "This is an example of a simple implementation of a neural network model. Similar, but not equal to \n",
    "\n",
    "> Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). A neural probabilistic language model. *Journal of machine learning research*, *3*(Feb), 1137-1155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmodels.corpora.moviedialog import MovieDialogCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'movie-dialogs'\n",
    "collection = 'lines'\n",
    "m = {'$match': {'character.movie.id': 'm42'}}\n",
    "p = {'$project': {'_id': 0, 'id': 1, 'text': 1}}\n",
    "pipeline = [m, p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m42 = MovieDialogCollection(db_name, collection, \n",
    "                              use_pos=False, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = m42.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing words and create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2w = {i:w for (i, w) in enumerate(V)}\n",
    "w2idx = {w:i for (i, w) in enumerate(V)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for doc, tokens in m42.get_tokens():\n",
    "    sequences.append([w2idx[t] for t in tokens])\n",
    "sequences = np.array(pad_sequences(sequences, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 106) (834, 1363)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the embedding layer\n",
    "The embedding layer is based on the size of the vocabulary and the length of input sequences, plus the number of dimensions for vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "E = Embedding(len(V), embedding_size, input_length=X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(E)\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(len(V), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 106, 50)           68150     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1363)              137663    \n",
      "=================================================================\n",
      "Total params: 276,313\n",
      "Trainable params: 276,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfio/Applications/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 7.2135 - accuracy: 0.0156\n",
      "Epoch 2/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 7.1450 - accuracy: 0.0300\n",
      "Epoch 3/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 6.5437 - accuracy: 0.0240\n",
      "Epoch 4/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.9276 - accuracy: 0.0240\n",
      "Epoch 5/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.7645 - accuracy: 0.0408\n",
      "Epoch 6/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.6573 - accuracy: 0.0408\n",
      "Epoch 7/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.6330 - accuracy: 0.0408\n",
      "Epoch 8/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.6102 - accuracy: 0.0408\n",
      "Epoch 9/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5990 - accuracy: 0.0408\n",
      "Epoch 10/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5933 - accuracy: 0.0408\n",
      "Epoch 11/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5901 - accuracy: 0.0408\n",
      "Epoch 12/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5819 - accuracy: 0.0408\n",
      "Epoch 13/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5815 - accuracy: 0.0408\n",
      "Epoch 14/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5734 - accuracy: 0.0408\n",
      "Epoch 15/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5676 - accuracy: 0.0408\n",
      "Epoch 16/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5553 - accuracy: 0.0408\n",
      "Epoch 17/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5426 - accuracy: 0.0408\n",
      "Epoch 18/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5299 - accuracy: 0.0408\n",
      "Epoch 19/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.5137 - accuracy: 0.0408\n",
      "Epoch 20/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4919 - accuracy: 0.0408\n",
      "Epoch 21/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4710 - accuracy: 0.0408\n",
      "Epoch 22/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4488 - accuracy: 0.0408\n",
      "Epoch 23/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 5.4257 - accuracy: 0.0408\n",
      "Epoch 24/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4048 - accuracy: 0.0408\n",
      "Epoch 25/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.3840 - accuracy: 0.0408\n",
      "Epoch 26/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 5.3663 - accuracy: 0.0408\n",
      "Epoch 27/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.3432 - accuracy: 0.0408\n",
      "Epoch 28/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.3205 - accuracy: 0.0408\n",
      "Epoch 29/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.3005 - accuracy: 0.0408\n",
      "Epoch 30/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.2758 - accuracy: 0.0408\n",
      "Epoch 31/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.2467 - accuracy: 0.0420\n",
      "Epoch 32/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.2202 - accuracy: 0.0432\n",
      "Epoch 33/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.1786 - accuracy: 0.0444\n",
      "Epoch 34/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.1394 - accuracy: 0.0444\n",
      "Epoch 35/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.0833 - accuracy: 0.0468\n",
      "Epoch 36/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.0291 - accuracy: 0.0480\n",
      "Epoch 37/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.9648 - accuracy: 0.0492\n",
      "Epoch 38/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.9013 - accuracy: 0.0492\n",
      "Epoch 39/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.8341 - accuracy: 0.0492\n",
      "Epoch 40/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.7708 - accuracy: 0.0600\n",
      "Epoch 41/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.6991 - accuracy: 0.0635\n",
      "Epoch 42/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.6323 - accuracy: 0.0612\n",
      "Epoch 43/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.5533 - accuracy: 0.0647\n",
      "Epoch 44/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.4788 - accuracy: 0.0899\n",
      "Epoch 45/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.4138 - accuracy: 0.0827\n",
      "Epoch 46/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.3423 - accuracy: 0.0983\n",
      "Epoch 47/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.2740 - accuracy: 0.0911\n",
      "Epoch 48/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.1980 - accuracy: 0.0947\n",
      "Epoch 49/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.1297 - accuracy: 0.1247\n",
      "Epoch 50/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.0617 - accuracy: 0.1247\n",
      "Epoch 51/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.9935 - accuracy: 0.1223\n",
      "Epoch 52/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.9218 - accuracy: 0.1295\n",
      "Epoch 53/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8621 - accuracy: 0.1343\n",
      "Epoch 54/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.7838 - accuracy: 0.1463\n",
      "Epoch 55/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.7115 - accuracy: 0.1403\n",
      "Epoch 56/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.6461 - accuracy: 0.1427\n",
      "Epoch 57/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.5879 - accuracy: 0.1535\n",
      "Epoch 58/100\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 3.5183 - accuracy: 0.1643\n",
      "Epoch 59/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.4687 - accuracy: 0.1463\n",
      "Epoch 60/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.4055 - accuracy: 0.1739\n",
      "Epoch 61/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.3380 - accuracy: 0.1835\n",
      "Epoch 62/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.2876 - accuracy: 0.1799\n",
      "Epoch 63/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.2263 - accuracy: 0.1954\n",
      "Epoch 64/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.1717 - accuracy: 0.2146\n",
      "Epoch 65/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.1251 - accuracy: 0.2182\n",
      "Epoch 66/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.0624 - accuracy: 0.2290\n",
      "Epoch 67/100\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 3.0187 - accuracy: 0.2494\n",
      "Epoch 68/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.9663 - accuracy: 0.2578\n",
      "Epoch 69/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 2.9160 - accuracy: 0.2626\n",
      "Epoch 70/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.8534 - accuracy: 0.2878\n",
      "Epoch 71/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.8085 - accuracy: 0.2782\n",
      "Epoch 72/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.7692 - accuracy: 0.3070\n",
      "Epoch 73/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.7151 - accuracy: 0.2986\n",
      "Epoch 74/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.6662 - accuracy: 0.3333\n",
      "Epoch 75/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.6288 - accuracy: 0.3585\n",
      "Epoch 76/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 2.5758 - accuracy: 0.3453\n",
      "Epoch 77/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.5265 - accuracy: 0.3657\n",
      "Epoch 78/100\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 2.4817 - accuracy: 0.3705\n",
      "Epoch 79/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.4347 - accuracy: 0.3957\n",
      "Epoch 80/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.3905 - accuracy: 0.4005\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 1ms/step - loss: 2.3499 - accuracy: 0.4173\n",
      "Epoch 82/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.3119 - accuracy: 0.4077\n",
      "Epoch 83/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.2667 - accuracy: 0.4257\n",
      "Epoch 84/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.2205 - accuracy: 0.4712\n",
      "Epoch 85/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.1819 - accuracy: 0.4580\n",
      "Epoch 86/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.1249 - accuracy: 0.4916\n",
      "Epoch 87/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.0740 - accuracy: 0.4808\n",
      "Epoch 88/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.0367 - accuracy: 0.5144\n",
      "Epoch 89/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 2.0040 - accuracy: 0.5300\n",
      "Epoch 90/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.9567 - accuracy: 0.5228\n",
      "Epoch 91/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.9139 - accuracy: 0.5432\n",
      "Epoch 92/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.8826 - accuracy: 0.5540\n",
      "Epoch 93/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.8327 - accuracy: 0.5432\n",
      "Epoch 94/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.7839 - accuracy: 0.5899\n",
      "Epoch 95/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.7480 - accuracy: 0.6091\n",
      "Epoch 96/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.7131 - accuracy: 0.5959\n",
      "Epoch 97/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.6754 - accuracy: 0.6103\n",
      "Epoch 98/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.6403 - accuracy: 0.6283\n",
      "Epoch 99/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.5980 - accuracy: 0.6415\n",
      "Epoch 100/100\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.5524 - accuracy: 0.6655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1500e2d50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'read', 'five', 'times', 'that', 'you', 'were', 'killed', 'in', 'five', 'different', 'places']\n",
      "['we', 'read', 'five', 'times', 'that', 'you', 'were', 'killed', 'in', 'five', 'different']\n"
     ]
    }
   ],
   "source": [
    "test = sequences[42]\n",
    "print([idx2w[x] for x in test if x != 0])\n",
    "ask = np.array([0] + test[:-1])\n",
    "print([idx2w[x] for x in ask if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\n"
     ]
    }
   ],
   "source": [
    "w = model.predict_classes(ask.reshape(1, -1))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7549209e-15, 5.3787658e-17, 5.2095036e-16, ..., 1.1419303e-15,\n",
       "        5.3773733e-16, 7.4884436e-17]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(ask.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "places\n"
     ]
    }
   ],
   "source": [
    "print(idx2w[w[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1363, 50])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
